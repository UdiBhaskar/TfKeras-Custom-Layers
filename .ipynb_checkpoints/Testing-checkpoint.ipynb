{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, Dropout, GRU, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2Seq import clayers\n",
    "from Seq2Seq import cactivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import CuDNNGRU, concatenate, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_SEQ_LEN = 30\n",
    "DECODER_SEQ_LEN = 20\n",
    "VOCAB_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0, 499, size=(2000, ENCODER_SEQ_LEN))\n",
    "y = np.random.randint(0, 499, size=(2000, DECODER_SEQ_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "class BahdanauAttention(layers.Layer):\n",
    "    \n",
    "    def __init__(self,units):\n",
    "        \n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = layers.Dense(units)\n",
    "        self.Ua = layers.Dense(units)\n",
    "        self.Va = layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        enc_out,dec_prev_hs = inputs\n",
    "        \n",
    "        # decprev_hs - Decoder hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = tf.expand_dims(dec_prev_hs, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.Va(tf.nn.tanh(self.Wa(hidden_with_time_axis) + self.Ua(enc_out)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, 1, hidden_size)\n",
    "        context_vector = attention_weights * enc_out\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        context_vector = tf.expand_dims(context_vector, 1)\n",
    "        \n",
    "        dec_prev_hs = tf.reshape(dec_prev_hs,(-1,16))\n",
    "        \n",
    "        return context_vector \n",
    "\n",
    "def encoder():\n",
    "    encoder_input = Input(shape=(ENCODER_SEQ_LEN,), name='encoder_input')\n",
    "\n",
    "    x_embedded = Embedding(input_dim=VOCAB_SIZE, output_dim=50, input_length=ENCODER_SEQ_LEN,\n",
    "                           mask_zero=True, name=\"embedding_layer1\")(encoder_input)\n",
    "    \n",
    "    gru_output, gru_state= GRU(16,activation='tanh', \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               return_state=True,return_sequences=True,name=\"Encoder_GRU\")(x_embedded)\n",
    "    return Model(inputs=encoder_input, outputs=[gru_output, gru_state, x_embedded._keras_mask])\n",
    "\n",
    "def OneStepDecoder():\n",
    "    \n",
    "    #inputs\n",
    "    input_decoder = Input(shape=(1,),name=\"dec_input\")\n",
    "    \n",
    "    input_state = Input(shape=(16,),name=\"Dec_states\")\n",
    "    \n",
    "    encoder_outputs = Input(shape=(ENCODER_SEQ_LEN,16,),name=\"EncoderStates\")\n",
    "        \n",
    "    #mask = Input(shape=(ENCODER_SEQ_LEN,), name='mask_encoder')\n",
    "    \n",
    "    # Embedding layers\n",
    "    dec_embdd = Embedding(input_dim=VOCAB_SIZE, output_dim=50,\n",
    "                      input_length=1,name=\"DecoderEmbedding1\")(input_decoder)\n",
    "    \n",
    "    \n",
    "    context_vector = BahdanauAttention(units=20)(inputs=[input_state, encoder_outputs])\n",
    "    \n",
    "    concat = concatenate([tf.cast(context_vector, dec_embdd.dtype), dec_embdd],name=\"concat\")\n",
    "    \n",
    "    decoder_output, Decoder_state = GRU(units=16,return_state=True,name=\"DecGRU\")(concat, initial_state=input_state)\n",
    "    \n",
    "    output = Dense(units=VOCAB_SIZE,activation=\"softmax\",name=\"DenseOut\")(decoder_output)\n",
    "    \n",
    "    return Model(inputs=[input_decoder, input_state, encoder_outputs],outputs=[output, Decoder_state],name=\"OneStepDecoder\")\n",
    "\n",
    "    #return Model(inputs=[input_encoder, decoder_input], outputs=[encoder_outputs, encoder_state, mask_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_decoder():\n",
    "    \n",
    "    input_encoder = Input(shape=(ENCODER_SEQ_LEN,), name='encoder_input_final')\n",
    "    decoder_input = Input(shape=(DECODER_SEQ_LEN,), name=\"Decoder_inout_final\")\n",
    "\n",
    "    output_encoder, encoder_state, mask_enc = encoder()(input_encoder)\n",
    "    \n",
    "    decoder_one_att = OneStepDecoder()\n",
    "    \n",
    "    all_outputs= []\n",
    "     \n",
    "    \n",
    "    for timestep in range(DECODER_SEQ_LEN):\n",
    "        \n",
    "        inputs = Lambda(lambda x: x[:,timestep:timestep+1])(decoder_input)\n",
    "        \n",
    "        output, encoder_state = decoder_one_att([inputs, encoder_state, output_encoder])\n",
    "        \n",
    "        output = Lambda(lambda x:  tf.expand_dims(x, 1))(output)\n",
    "        \n",
    "        all_outputs.append(output)\n",
    "        \n",
    "        \n",
    "    decoder_outputs = Lambda(lambda x: tf.keras.backend.concatenate(all_outputs,1))(all_outputs)\n",
    "    \n",
    "    return Model(inputs=[encoder_input, decoder_input], outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 20:38:36.505398 15512 deprecation.py:506] From C:\\Users\\APPLIED AI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0901 20:38:36.540991 15512 deprecation.py:506] From C:\\Users\\APPLIED AI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0901 20:38:37.058603 15512 deprecation.py:323] From C:\\Users\\APPLIED AI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 1, 1, 30, 16), (None, 1, 50)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-697de1085773>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-5014b2581cbb>\u001b[0m in \u001b[0;36mencoder_decoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moutput_encoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_enc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_encoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdecoder_one_att\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneStepDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mall_outputs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-375b1e5cbf2c>\u001b[0m in \u001b[0;36mOneStepDecoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mcontext_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBahdanauAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_embdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_embdd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"concat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecoder_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"DecGRU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m   \"\"\"\n\u001b[1;32m--> 687\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[1;31m# Wrapping `call` function in autograph to allow for dynamic control\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m       \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m     \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(instance, input_shape)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    389\u001b[0m                        \u001b[1;34m'inputs with matching shapes '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                        \u001b[1;34m'except for the concat axis. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                        'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 1, 1, 30, 16), (None, 1, 50)]"
     ]
    }
   ],
   "source": [
    "EC = encoder_decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'model/Encoder_GRU/transpose_2:0' shape=(?, 30, 16) dtype=float32>,\n",
       " <tf.Tensor 'model/Encoder_GRU/while/Exit_4:0' shape=(?, 16) dtype=float32>,\n",
       " <tf.Tensor 'model/tf_op_layer_embedding_layer1/NotEqual/embedding_layer1/NotEqual:0' shape=(?, 30) dtype=bool>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Encoder_GRU_1/transpose_2:0' shape=(?, 30, 16) dtype=float32>,\n",
       " <tf.Tensor 'Encoder_GRU_1/while/Exit_4:0' shape=(?, 16) dtype=float32>,\n",
       " <tf.Tensor 'embedding_layer_1/NotEqual:0' shape=(?, 30) dtype=bool>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = OneStepDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"OneStepDecoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Dec_states (InputLayer)         [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncoderStates (InputLayer)      [(None, 30, 16)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention_1 (BahdanauA (None, 16)           681         Dec_states[0][0]                 \n",
      "                                                                 EncoderStates[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 16)]      0           bahdanau_attention_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dec_input (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Cast_1 (TensorFlowO [(None, 1, 16)]      0           tf_op_layer_ExpandDims_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "DecoderEmbedding (Embedding)    (None, 1, 50)        25000       dec_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 1, 66)        0           tf_op_layer_Cast_1[0][0]         \n",
      "                                                                 DecoderEmbedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "DecGRU (CuDNNGRU)               [(None, 16), (None,  4032        concat[0][0]                     \n",
      "                                                                 Dec_states[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "DenseOut (Dense)                (None, 500)          8500        DecGRU[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 38,213\n",
      "Trainable params: 38,213\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = decoder.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoderHt': <tf.Tensor 'Dec_states_1:0' shape=(?, 16) dtype=float32>,\n",
       " 'enocderHs': <tf.Tensor 'EncoderStates_1:0' shape=(?, 30, 16) dtype=float32>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2Seq import clayers\n",
    "from Seq2Seq import cactivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 19:26:56.062106 19544 deprecation.py:506] From C:\\Users\\APPLIED AI\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "input_encoder = Input(shape=(299,30),name='encoder_input',dtype=tf.float64)\n",
    "input_encoder2 = Input(shape=(18,),name='encoder_input1', dtype=tf.float64)\n",
    "enc = clayers.BahdanauAttention(20)({'enocderHs':input_encoder, \"decoderHt\":input_encoder2})\n",
    "ec = Model(inputs=[input_encoder,input_encoder2], outputs=enc,name=\"Encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input1 (InputLayer)     [(None, 18)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input (InputLayer)      [(None, 299, 30)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt ((None, 1, 30), (Non 1001        encoder_input1[0][0]             \n",
      "                                                                 encoder_input[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,001\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lay = ec.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enocderHs': (None, 299, 30), 'decoderHt': (None, 18)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'bahdanau_attention/bahdanau_attentionWa/kernel:0' shape=(18, 20) dtype=float64>,\n",
       " <tf.Variable 'bahdanau_attention/bahdanau_attentionUa/kernel:0' shape=(30, 20) dtype=float64>,\n",
       " <tf.Variable 'bahdanau_attention/bahdanau_attentionUa/bias:0' shape=(20,) dtype=float64>,\n",
       " <tf.Variable 'bahdanau_attention/bahdanau_attentionVa/kernel:0' shape=(20, 1) dtype=float64>,\n",
       " <tf.Variable 'bahdanau_attention/bahdanau_attentionVa/bias:0' shape=(1,) dtype=float64>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out = np.random.rand(1,299,30)\n",
    "dec_time = np.random.rand(1,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ec.predict([enc_out,dec_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46847242, 0.52131588, 0.52624267, 0.47991199, 0.49257776,\n",
       "         0.51926419, 0.51109958, 0.48879396, 0.4811505 , 0.50310391,\n",
       "         0.5176188 , 0.55013205, 0.54318154, 0.50026701, 0.48266005,\n",
       "         0.52572615, 0.53378751, 0.51048531, 0.5137893 , 0.5065158 ,\n",
       "         0.44587368, 0.5221608 , 0.50218066, 0.48748987, 0.46467854,\n",
       "         0.47374507, 0.55339898, 0.46903254, 0.54923708, 0.46337889]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00608809],\n",
       "        [0.00597161],\n",
       "        [0.00287722],\n",
       "        [0.00337029],\n",
       "        [0.00265592],\n",
       "        [0.00210088],\n",
       "        [0.00252202],\n",
       "        [0.00241118],\n",
       "        [0.00370802],\n",
       "        [0.0030037 ],\n",
       "        [0.00459967],\n",
       "        [0.00197777],\n",
       "        [0.00230325],\n",
       "        [0.0018521 ],\n",
       "        [0.00328029],\n",
       "        [0.00290602],\n",
       "        [0.00340892],\n",
       "        [0.00428554],\n",
       "        [0.00372664],\n",
       "        [0.00380746],\n",
       "        [0.00295794],\n",
       "        [0.00213594],\n",
       "        [0.00245329],\n",
       "        [0.00294017],\n",
       "        [0.00428336],\n",
       "        [0.0021236 ],\n",
       "        [0.00237624],\n",
       "        [0.00460721],\n",
       "        [0.00330059],\n",
       "        [0.00282156],\n",
       "        [0.0034899 ],\n",
       "        [0.00453992],\n",
       "        [0.00354604],\n",
       "        [0.00255882],\n",
       "        [0.00301919],\n",
       "        [0.00255568],\n",
       "        [0.00342336],\n",
       "        [0.00284301],\n",
       "        [0.00518907],\n",
       "        [0.00469493],\n",
       "        [0.0036737 ],\n",
       "        [0.00432879],\n",
       "        [0.00497782],\n",
       "        [0.0018269 ],\n",
       "        [0.00304006],\n",
       "        [0.00273376],\n",
       "        [0.00170957],\n",
       "        [0.00388125],\n",
       "        [0.00381509],\n",
       "        [0.00318294],\n",
       "        [0.00671525],\n",
       "        [0.00391782],\n",
       "        [0.00311865],\n",
       "        [0.00377415],\n",
       "        [0.00346169],\n",
       "        [0.00282886],\n",
       "        [0.00283856],\n",
       "        [0.00365047],\n",
       "        [0.00563848],\n",
       "        [0.00248583],\n",
       "        [0.00342263],\n",
       "        [0.0032542 ],\n",
       "        [0.00225169],\n",
       "        [0.0024527 ],\n",
       "        [0.00408305],\n",
       "        [0.00303826],\n",
       "        [0.00381944],\n",
       "        [0.00421371],\n",
       "        [0.00556057],\n",
       "        [0.00232721],\n",
       "        [0.00269389],\n",
       "        [0.0026293 ],\n",
       "        [0.00352188],\n",
       "        [0.00206728],\n",
       "        [0.0018725 ],\n",
       "        [0.0039882 ],\n",
       "        [0.00202405],\n",
       "        [0.00452308],\n",
       "        [0.00199711],\n",
       "        [0.00288772],\n",
       "        [0.00304097],\n",
       "        [0.0029121 ],\n",
       "        [0.00316944],\n",
       "        [0.00338028],\n",
       "        [0.00273524],\n",
       "        [0.00360633],\n",
       "        [0.00315293],\n",
       "        [0.00306617],\n",
       "        [0.00418418],\n",
       "        [0.00210425],\n",
       "        [0.00347453],\n",
       "        [0.00309557],\n",
       "        [0.00267558],\n",
       "        [0.00382381],\n",
       "        [0.00334978],\n",
       "        [0.00216926],\n",
       "        [0.00374857],\n",
       "        [0.00216109],\n",
       "        [0.0020338 ],\n",
       "        [0.00287464],\n",
       "        [0.00439359],\n",
       "        [0.00337895],\n",
       "        [0.00359764],\n",
       "        [0.00252551],\n",
       "        [0.00260324],\n",
       "        [0.00272949],\n",
       "        [0.00155029],\n",
       "        [0.00348912],\n",
       "        [0.00380379],\n",
       "        [0.00269276],\n",
       "        [0.00438081],\n",
       "        [0.00283772],\n",
       "        [0.0032288 ],\n",
       "        [0.00399642],\n",
       "        [0.00271912],\n",
       "        [0.00343468],\n",
       "        [0.00224934],\n",
       "        [0.00213318],\n",
       "        [0.00289011],\n",
       "        [0.00425868],\n",
       "        [0.00320695],\n",
       "        [0.00387888],\n",
       "        [0.00294269],\n",
       "        [0.00413015],\n",
       "        [0.00265806],\n",
       "        [0.00388706],\n",
       "        [0.0042437 ],\n",
       "        [0.0029657 ],\n",
       "        [0.00268784],\n",
       "        [0.00400584],\n",
       "        [0.0029412 ],\n",
       "        [0.00287737],\n",
       "        [0.00406127],\n",
       "        [0.00404916],\n",
       "        [0.00281512],\n",
       "        [0.00297849],\n",
       "        [0.00531171],\n",
       "        [0.00286921],\n",
       "        [0.00381704],\n",
       "        [0.00218591],\n",
       "        [0.00408944],\n",
       "        [0.00323585],\n",
       "        [0.00271432],\n",
       "        [0.00335632],\n",
       "        [0.00269658],\n",
       "        [0.00217372],\n",
       "        [0.00435899],\n",
       "        [0.00332357],\n",
       "        [0.00203421],\n",
       "        [0.00328731],\n",
       "        [0.00419838],\n",
       "        [0.00398718],\n",
       "        [0.00309892],\n",
       "        [0.00529983],\n",
       "        [0.00239731],\n",
       "        [0.00440963],\n",
       "        [0.00506838],\n",
       "        [0.00390615],\n",
       "        [0.00419015],\n",
       "        [0.00244671],\n",
       "        [0.00200945],\n",
       "        [0.00197462],\n",
       "        [0.00391656],\n",
       "        [0.0024934 ],\n",
       "        [0.00536348],\n",
       "        [0.00329063],\n",
       "        [0.00484869],\n",
       "        [0.0040503 ],\n",
       "        [0.00175261],\n",
       "        [0.00397392],\n",
       "        [0.00319019],\n",
       "        [0.00184365],\n",
       "        [0.00288709],\n",
       "        [0.00408269],\n",
       "        [0.00357813],\n",
       "        [0.00336541],\n",
       "        [0.00257908],\n",
       "        [0.0031468 ],\n",
       "        [0.00241012],\n",
       "        [0.004315  ],\n",
       "        [0.00381259],\n",
       "        [0.00226606],\n",
       "        [0.00352625],\n",
       "        [0.00327658],\n",
       "        [0.00366348],\n",
       "        [0.00388761],\n",
       "        [0.00475355],\n",
       "        [0.00254411],\n",
       "        [0.00303374],\n",
       "        [0.00245675],\n",
       "        [0.00186365],\n",
       "        [0.00286454],\n",
       "        [0.00472557],\n",
       "        [0.00380681],\n",
       "        [0.00275896],\n",
       "        [0.00538067],\n",
       "        [0.00298871],\n",
       "        [0.00543777],\n",
       "        [0.00376332],\n",
       "        [0.00333495],\n",
       "        [0.00310683],\n",
       "        [0.00310811],\n",
       "        [0.00332895],\n",
       "        [0.00236045],\n",
       "        [0.00308767],\n",
       "        [0.00341961],\n",
       "        [0.00309417],\n",
       "        [0.00375219],\n",
       "        [0.00329564],\n",
       "        [0.00540265],\n",
       "        [0.00288123],\n",
       "        [0.00310725],\n",
       "        [0.00262666],\n",
       "        [0.00388562],\n",
       "        [0.00404068],\n",
       "        [0.00421779],\n",
       "        [0.00372012],\n",
       "        [0.00190892],\n",
       "        [0.00324324],\n",
       "        [0.00241061],\n",
       "        [0.00296297],\n",
       "        [0.0040991 ],\n",
       "        [0.00425462],\n",
       "        [0.00323105],\n",
       "        [0.00292257],\n",
       "        [0.00253587],\n",
       "        [0.00277407],\n",
       "        [0.00176794],\n",
       "        [0.00490079],\n",
       "        [0.00206527],\n",
       "        [0.00327958],\n",
       "        [0.00265112],\n",
       "        [0.00388068],\n",
       "        [0.00264174],\n",
       "        [0.00249378],\n",
       "        [0.00340127],\n",
       "        [0.00506307],\n",
       "        [0.00353262],\n",
       "        [0.00209853],\n",
       "        [0.00397167],\n",
       "        [0.00374881],\n",
       "        [0.00260666],\n",
       "        [0.00211799],\n",
       "        [0.00442547],\n",
       "        [0.00464644],\n",
       "        [0.00397095],\n",
       "        [0.0029418 ],\n",
       "        [0.00346617],\n",
       "        [0.00376648],\n",
       "        [0.00316035],\n",
       "        [0.00378665],\n",
       "        [0.00244656],\n",
       "        [0.00509185],\n",
       "        [0.00318551],\n",
       "        [0.00542725],\n",
       "        [0.0030414 ],\n",
       "        [0.00261937],\n",
       "        [0.00359105],\n",
       "        [0.00345848],\n",
       "        [0.00289317],\n",
       "        [0.00474665],\n",
       "        [0.00247229],\n",
       "        [0.00499639],\n",
       "        [0.0024275 ],\n",
       "        [0.00517225],\n",
       "        [0.00176946],\n",
       "        [0.00423189],\n",
       "        [0.00228027],\n",
       "        [0.0061041 ],\n",
       "        [0.00380631],\n",
       "        [0.00397002],\n",
       "        [0.00248955],\n",
       "        [0.00357231],\n",
       "        [0.00263423],\n",
       "        [0.00318147],\n",
       "        [0.00219235],\n",
       "        [0.00287786],\n",
       "        [0.00375116],\n",
       "        [0.00291701],\n",
       "        [0.00270147],\n",
       "        [0.00395981],\n",
       "        [0.00265218],\n",
       "        [0.003836  ],\n",
       "        [0.00505193],\n",
       "        [0.00472961],\n",
       "        [0.00480812],\n",
       "        [0.00403296],\n",
       "        [0.00327788],\n",
       "        [0.00294616],\n",
       "        [0.00261981],\n",
       "        [0.00390598],\n",
       "        [0.00382665],\n",
       "        [0.00462538],\n",
       "        [0.00178463],\n",
       "        [0.00234444],\n",
       "        [0.00224254],\n",
       "        [0.004606  ],\n",
       "        [0.00182059],\n",
       "        [0.00311557]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.rand(1,299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = z>0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 299)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder1 = Input(shape=(299,30),name='encoder_input1')\n",
    "input_encoder21 = Input(shape=(18,),name='encoder_input11')\n",
    "enc1 = clayers.BahdanauAttention(20, dropout_rate=0.5)({'enocderHs':input_encoder1, \"decoderHt\":input_encoder21}, mask= mask )\n",
    "ec1 = Model(inputs=[input_encoder1,input_encoder21], outputs=enc1,name=\"Encoder1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec1.set_weights(ec.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = ec1.predict([enc_out,dec_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.58171823, 0.58884138, 0.63167508, 0.59266423, 0.57352353,\n",
       "         0.64137262, 0.61472036, 0.57511042, 0.54140157, 0.59140166,\n",
       "         0.62866379, 0.62345499, 0.63262644, 0.57587823, 0.57890117,\n",
       "         0.63011234, 0.6517398 , 0.58373807, 0.61133019, 0.60504147,\n",
       "         0.53413561, 0.59826606, 0.61382586, 0.55741361, 0.56208113,\n",
       "         0.61379471, 0.65811258, 0.5230791 , 0.64002367, 0.51780918]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.46847242, 0.52131588, 0.52624267, 0.47991199, 0.49257776,\n",
       "         0.51926419, 0.51109958, 0.48879396, 0.4811505 , 0.50310391,\n",
       "         0.5176188 , 0.55013205, 0.54318154, 0.50026701, 0.48266005,\n",
       "         0.52572615, 0.53378751, 0.51048531, 0.5137893 , 0.5065158 ,\n",
       "         0.44587368, 0.5221608 , 0.50218066, 0.48748987, 0.46467854,\n",
       "         0.47374507, 0.55339898, 0.46903254, 0.54923708, 0.46337889]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00301616],\n",
       "        [0.00810712],\n",
       "        [0.00499735],\n",
       "        [0.00687517],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00482276],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01093184],\n",
       "        [0.        ],\n",
       "        [0.00492609],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00574892],\n",
       "        [0.0044887 ],\n",
       "        [0.        ],\n",
       "        [0.00659918],\n",
       "        [0.00267949],\n",
       "        [0.        ],\n",
       "        [0.00556889],\n",
       "        [0.        ],\n",
       "        [0.00745138],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00794445],\n",
       "        [0.00622469],\n",
       "        [0.        ],\n",
       "        [0.00459757],\n",
       "        [0.        ],\n",
       "        [0.00414036],\n",
       "        [0.00719009],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0078114 ],\n",
       "        [0.00547404],\n",
       "        [0.00926585],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00598648],\n",
       "        [0.00537305],\n",
       "        [0.00544159],\n",
       "        [0.        ],\n",
       "        [0.00706618],\n",
       "        [0.00566358],\n",
       "        [0.00355451],\n",
       "        [0.00843726],\n",
       "        [0.        ],\n",
       "        [0.0055623 ],\n",
       "        [0.00362055],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00555787],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00586197],\n",
       "        [0.        ],\n",
       "        [0.00569322],\n",
       "        [0.00645456],\n",
       "        [0.00604741],\n",
       "        [0.00553123],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00736051],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00565184],\n",
       "        [0.0073338 ],\n",
       "        [0.        ],\n",
       "        [0.00636964],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0070199 ],\n",
       "        [0.0049055 ],\n",
       "        [0.00943493],\n",
       "        [0.0067743 ],\n",
       "        [0.        ],\n",
       "        [0.00742632],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00371147],\n",
       "        [0.00519691],\n",
       "        [0.        ],\n",
       "        [0.00687231],\n",
       "        [0.        ],\n",
       "        [0.00477699],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00542377],\n",
       "        [0.        ],\n",
       "        [0.0050506 ],\n",
       "        [0.00677568],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01304433],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0095769 ],\n",
       "        [0.00776615],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00576006],\n",
       "        [0.00587091],\n",
       "        [0.00358655],\n",
       "        [0.00768142],\n",
       "        [0.00425683],\n",
       "        [0.        ],\n",
       "        [0.0088031 ],\n",
       "        [0.        ],\n",
       "        [0.01024224],\n",
       "        [0.00593597],\n",
       "        [0.00668507],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0082673 ],\n",
       "        [0.00637441],\n",
       "        [0.00363816],\n",
       "        [0.00645999],\n",
       "        [0.        ],\n",
       "        [0.00632968],\n",
       "        [0.00782288],\n",
       "        [0.        ],\n",
       "        [0.00910949],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01055916],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00363771],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00711835],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00590053],\n",
       "        [0.        ],\n",
       "        [0.00837155],\n",
       "        [0.00632628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00380276],\n",
       "        [0.00515492],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00787019],\n",
       "        [0.        ],\n",
       "        [0.00439684],\n",
       "        [0.00687767],\n",
       "        [0.00787328],\n",
       "        [0.00492918],\n",
       "        [0.00575756],\n",
       "        [0.        ],\n",
       "        [0.00772955],\n",
       "        [0.00524195],\n",
       "        [0.        ],\n",
       "        [0.00483858],\n",
       "        [0.        ],\n",
       "        [0.00511585],\n",
       "        [0.        ],\n",
       "        [0.01079846],\n",
       "        [0.        ],\n",
       "        [0.00881487],\n",
       "        [0.00550021],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00623188],\n",
       "        [0.0090032 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00818864],\n",
       "        [0.        ],\n",
       "        [0.00891466],\n",
       "        [0.00743022],\n",
       "        [0.        ],\n",
       "        [0.00820452],\n",
       "        [0.00398005],\n",
       "        [0.00908382],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00470119],\n",
       "        [0.00869191],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00746817],\n",
       "        [0.00501568],\n",
       "        [0.        ],\n",
       "        [0.0063625 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00799865],\n",
       "        [0.00468579],\n",
       "        [0.01081072],\n",
       "        [0.        ],\n",
       "        [0.00582926],\n",
       "        [0.00463673],\n",
       "        [0.00501992],\n",
       "        [0.00723297],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00456614],\n",
       "        [0.        ],\n",
       "        [0.00527864],\n",
       "        [0.00739109],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00602652],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00845088],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00652124],\n",
       "        [0.00897419],\n",
       "        [0.        ],\n",
       "        [0.01165017],\n",
       "        [0.00627252],\n",
       "        [0.00473349],\n",
       "        [0.00468993],\n",
       "        [0.00682551],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00565166],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00680455],\n",
       "        [0.        ],\n",
       "        [0.00576064],\n",
       "        [0.00491848],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00973476],\n",
       "        [0.01290685],\n",
       "        [0.00582231],\n",
       "        [0.00411262],\n",
       "        [0.        ],\n",
       "        [0.0103889 ],\n",
       "        [0.        ],\n",
       "        [0.00447497],\n",
       "        [0.00607293],\n",
       "        [0.00642467],\n",
       "        [0.0067121 ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.0102432 ],\n",
       "        [0.00587158],\n",
       "        [0.00554895],\n",
       "        [0.00684751],\n",
       "        [0.00323858],\n",
       "        [0.        ],\n",
       "        [0.01016146],\n",
       "        [0.00572401],\n",
       "        [0.        ],\n",
       "        [0.00864399],\n",
       "        [0.00485953]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention1(Layer):\n",
    "    \n",
    "    def __init__(self,units):\n",
    "        \n",
    "        super(BahdanauAttention1, self).__init__()\n",
    "\n",
    "        self.Wa = layers.Dense(units)\n",
    "        self.Ua = layers.Dense(units)\n",
    "        self.Va = layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "    \n",
    "        assert len(inputs) ==2, \"inputs length must be 2 but got {}\".format(len(inputs))\n",
    "\n",
    "        enc_out, dec_prev_hs = inputs\n",
    "\n",
    "        #assert len(enc_out.shape) == 3, \"Encoder Hiddenstates/output should be 3 dim ( B x T x H ), but got {} dim\".format(len(enc_out.shape))\n",
    "\n",
    "        #assert len(dec_prev_hs.shape) == 2, \"Decoder Hidden/output should be 2 dim (B x H), but got {} dim\".format(len(dec_prev_hs.shape))\n",
    "        \n",
    "        # decprev_hs - Decoder hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        hidden_with_time_axis = tf.expand_dims(dec_prev_hs, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.Va(tf.nn.tanh(self.Wa(hidden_with_time_axis) + self.Ua(enc_out)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        score = tf.squeeze(score,axis=2)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(score, axis=-1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, 1, hidden_size)\n",
    "        #attention_weights = tf.squeeze(attention_weights,[2])\n",
    "        #context_vector = attention_weights * enc_out\n",
    "        context_vector = tf.tensordot(attention_weights, enc_out, axes=[1,1])\n",
    "        \n",
    "        #context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        #context_vector = tf.expand_dims(context_vector, 1)\n",
    "\n",
    "        return context_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_encoder1 = Input(shape=(299,30),name='encoder_input1')\n",
    "input_encoder21 = Input(shape=(18,),name='encoder_input11')\n",
    "enc1 = BahdanauAttention1(20)([input_encoder1,input_encoder21])\n",
    "ec1 = Model(inputs=[input_encoder1,input_encoder21], outputs=enc1,name=\"Encoder1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input1 (InputLayer)     (None, 299, 30)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input11 (InputLayer)    (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention1_17 (Bahdana (None, None, 30)     1021        encoder_input1[0][0]             \n",
      "                                                                 encoder_input11[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,021\n",
      "Trainable params: 1,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ec1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable bahdanau_attention/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bahdanau_attention/dense/kernel/class tensorflow::Var does not exist.\n\t [[node bahdanau_attention/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py:34) ]]\n\nCaused by op 'bahdanau_attention/dense/kernel/Read/ReadVariableOp', defined at:\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-78-344da863ccf6>\", line 4, in <module>\n    enc = Layers.BahdanauAttention(20)([input_encoder,input_encoder2])\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py\", line 34, in call\n    # decprev_hs - Decoder hidden shape == (batch_size, hidden size)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\", line 949, in build\n    trainable=True)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 145, in make_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 446, in _init_from_args\n    value = self._read_variable_op()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\", line 549, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable bahdanau_attention/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bahdanau_attention/dense/kernel/class tensorflow::Var does not exist.\n\t [[node bahdanau_attention/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py:34) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Error while reading resource variable bahdanau_attention/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bahdanau_attention/dense/kernel/class tensorflow::Var does not exist.\n\t [[{{node bahdanau_attention/dense/kernel/Read/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-255-9d2e9eaf424f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mec1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m       \u001b[0mweights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   2817\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2818\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2819\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2820\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2821\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Error while reading resource variable bahdanau_attention/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bahdanau_attention/dense/kernel/class tensorflow::Var does not exist.\n\t [[node bahdanau_attention/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py:34) ]]\n\nCaused by op 'bahdanau_attention/dense/kernel/Read/ReadVariableOp', defined at:\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n    self._run_once()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n    handle._run()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2880, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3057, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3248, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-78-344da863ccf6>\", line 4, in <module>\n    enc = Layers.BahdanauAttention(20)([input_encoder,input_encoder2])\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py\", line 34, in call\n    # decprev_hs - Decoder hidden shape == (batch_size, hidden size)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\", line 949, in build\n    trainable=True)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py\", line 145, in make_variable\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2488, in default_variable_creator\n    import_scope=import_scope)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 294, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 446, in _init_from_args\n    value = self._read_variable_op()\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 728, in _read_variable_op\n    self._dtype)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\", line 549, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\AAIC 2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Error while reading resource variable bahdanau_attention/dense/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bahdanau_attention/dense/kernel/class tensorflow::Var does not exist.\n\t [[node bahdanau_attention/dense/kernel/Read/ReadVariableOp (defined at C:\\Users\\AAIC 2\\AAIC\\Seq2Seq\\Layers.py:34) ]]\n"
     ]
    }
   ],
   "source": [
    "ec1.set_weights(ec.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.48155642, 0.4391204 , 0.49610093, 0.4956632 , 0.5051189 ,\n",
       "         0.5419042 , 0.5046029 , 0.45739356, 0.5102644 , 0.5023593 ,\n",
       "         0.5452222 , 0.5163187 , 0.48430276, 0.47160408, 0.5260588 ,\n",
       "         0.49398088, 0.48618364, 0.5081909 , 0.51142097, 0.48695618,\n",
       "         0.51736784, 0.50500995, 0.4929487 , 0.47522777, 0.52542967,\n",
       "         0.49673676, 0.5032436 , 0.5038543 , 0.5095011 , 0.50547886]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec1.predict([enc_out,dec_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input1 (InputLayer)     (None, 299, 30)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_input11 (InputLayer)    (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention1_11 (Bahdana (None, 1, 299, 30)   1021        encoder_input1[0][0]             \n",
      "                                                                 encoder_input11[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 1,021\n",
      "Trainable params: 1,021\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ec1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Seq2Seq.cactivations import softmax, hardmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.nn.softmax([2.,5.,3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04201007, 0.8437947 , 0.11419519], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04201007, 0.8437947 , 0.11419519], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(softmax([2.,5.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.random.rand(3,5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.02611115, 0.10637641],\n",
       "        [0.32108248, 0.21443138],\n",
       "        [0.19194634, 0.13275355],\n",
       "        [0.91394329, 0.83391005],\n",
       "        [0.50612032, 0.03669808]],\n",
       "\n",
       "       [[0.68119429, 0.28752281],\n",
       "        [0.98561268, 0.07282184],\n",
       "        [0.97173626, 0.88691413],\n",
       "        [0.26449125, 0.6861028 ],\n",
       "        [0.17513496, 0.89407585]],\n",
       "\n",
       "       [[0.87621288, 0.01600687],\n",
       "        [0.95807974, 0.07338225],\n",
       "        [0.15134578, 0.04977872],\n",
       "        [0.01208139, 0.97130783],\n",
       "        [0.8065923 , 0.21370335]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]],\n",
       "\n",
       "       [[1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(hardmax(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sess.run(tf.one_hot(tf.math.argmax(t,-1),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyy = sess.run(tf.nn.softmax(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26509855, 0.70553496, 0.41480945, 0.71259458, 0.30775338],\n",
       "       [0.93292848, 0.01112402, 0.10069279, 0.16851184, 0.64116961]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tyy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472848, 0.66524094], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.softmax([1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09003057, 0.24472848, 0.66524094], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cactivations.softmax([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.array([1.,2.,3.]) + np.array([0,1,0]) * -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11920292, 0.        , 0.88079708])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.nn.softmax(zz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11920292, 0.        , 0.88079708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cactivations.softmax(zz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0830 12:29:44.922322 19332 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0830 12:29:45.020347 19332 deprecation.py:323] From C:\\Users\\APPLIED AI\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\sparsemax\\python\\ops\\sparsemax.py:92: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.contrib.sparsemax.sparsemax([[1.,2.,3.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0830 12:30:26.636062 19332 deprecation_wrapper.py:119] From D:\\ML\\TfKeras Custom Layers\\Seq2Seq\\cactivations.py:51: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cactivations.sparsemax([[1.,2.,3.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.contrib.sparsemax.sparsemax(zz.reshape(1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.random(size=(1,10)) * 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.26730828, 0.04262891, 3.09585926, 4.90840568, 4.73109869,\n",
       "        3.56666077, 3.33952132, 0.74360572, 2.42749901, 3.13652687]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.58865349, 0.41134651,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.contrib.sparsemax.sparsemax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.58865349, 0.41134651,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cactivations.sparsemax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.58865349, 0.41134651,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(cactivations.get('sparsemax')(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test + np.array([[1, 1, 0, 0, 0, 1, 0, 0, 0, 1]]) * -1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.99999998e+08, -9.99999997e+08,  4.15061696e+00,\n",
       "         5.37140344e+00,  2.39380946e+00, -9.99999997e+08,\n",
       "         4.26024837e+00,  1.18268916e+00,  5.32399158e+00,\n",
       "        -9.99999996e+08]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.52370593, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47629407, 0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.contrib.sparsemax.sparsemax(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cactivations.hardmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.random.rand(1, 4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = sess.run(tf.squeeze(t, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.37513276],\n",
       "        [0.38091136],\n",
       "        [0.45481904],\n",
       "        [0.06901354]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 2.2, 4, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 2.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin((num - a)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15, -0.15,  0.05,  1.85,  4.85])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_least(a, num):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
